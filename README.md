# Web Data Harvester

[![Python](https://img.shields.io/badge/python-3.12-blue?logo=python)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/docker-ready-blue?logo=docker)](https://www.docker.com/)
[![Asyncio](https://img.shields.io/badge/asyncio-supported-brightgreen)](https://docs.python.org/3/library/asyncio.html)
[![Redis](https://img.shields.io/badge/redis-used-red?logo=redis)](https://redis.io/)
[![Flask](https://img.shields.io/badge/flask-web--app-darkgreen?logo=flask)](https://flask.palletsprojects.com/)

---

Aplikacja do asynchronicznego scrapowania, selekcjonowania i prezentacji danych z witryn internetowych w architekturze rozproszonej. Projekt na kurs **Przetwarzanie rÃ³wnolegÅ‚e i rozproszone** (2024/25).

---

## ğŸ—‚ï¸ Opis projektu

Web Data Harvester to aplikacja, ktÃ³ra pobiera, selekcjonuje i prezentuje dane (tytuÅ‚, cena, ocena, dostÄ™pnoÅ›Ä‡, opis, okÅ‚adka) z serwisu [books.toscrape.com](https://books.toscrape.com/). System skÅ‚ada siÄ™ z trzech kontenerÃ³w Docker: asynchronicznego scrapera, aplikacji webowej (Flask) oraz bazy danych Redis. Wszystkie komponenty sÄ… zarzÄ…dzane przez `docker-compose`.

---

## ğŸ› ï¸ Technologie

- **Python 3.12** â€“ gÅ‚Ã³wny jÄ™zyk programowania
- **asyncio, aiohttp** â€“ asynchroniczne pobieranie danych
- **BeautifulSoup** â€“ parsowanie HTML
- **Redis** â€“ baza danych do przechowywania rekordÃ³w
- **Flask** â€“ aplikacja webowa (interfejs uÅ¼ytkownika)
- **Docker** â€“ konteneryzacja i Å‚atwe wdraÅ¼anie

---

## ğŸ“‚ Struktura katalogÃ³w

![Struktura](img/img1.png)

---

## âš¡ Szybki start

1. **Wymagania:**  
   - Docker + Docker Compose

2. **Budowanie i uruchomienie:**
   ```bash
   docker-compose up --build
   ```


3. **DostÄ™p:**  
Aplikacja webowa: [http://localhost:5000](http://localhost:5000)

---

## ğŸ§© GÅ‚Ã³wne pliki

- `scraper/scraper.py` â€“ asynchroniczny scraper (pobieranie i zapis danych)
- `web/app.py` â€“ aplikacja Flask (interfejs uÅ¼ytkownika)
- `web/templates/` â€“ szablony HTML
- `web/static/style.css` â€“ style interfejsu
- `docker-compose.yml` â€“ konfiguracja usÅ‚ug
- `scraper/Dockerfile`, `web/Dockerfile` â€“ pliki budujÄ…ce kontenery

---

## ğŸ–¼ï¸ Zrzuty ekranu

### Budowanie kontenerÃ³w
![Budowanie kontenerÃ³w](img/img2.png)
![Budowanie kontenerÃ³w 2](img/img3.png)

### Interfejs aplikacji
![Widok katalogu](img/img4.png)
![Widok szczegÃ³Å‚Ã³w ksiÄ…Å¼ki](img/img5.png)

---

## ğŸ“ Wnioski techniczne

Aplikacja zostaÅ‚a zrealizowana jako system rozproszony, podzielony na trzy kontenery: scraper, aplikacjÄ™ webowÄ… (Flask) oraz bazÄ™ danych Redis, zarzÄ…dzane przez `docker-compose`. Scraper wykorzystuje asynchronicznoÅ›Ä‡ (asyncio, aiohttp) oraz BeautifulSoup do wydajnego pobierania i przetwarzania danych, ktÃ³re sÄ… nastÄ™pnie zapisywane w Redis. Profil danych obejmuje wiele grup informacji, speÅ‚niajÄ…c wymagania projektowe. Interfejs webowy umoÅ¼liwia wygodne przeglÄ…danie i filtrowanie danych. CaÅ‚oÅ›Ä‡ jest Å‚atwa do wdroÅ¼enia i skalowania dziÄ™ki konteneryzacji. Projekt speÅ‚nia wszystkie zaÅ‚oÅ¼enia techniczne i jest gotowy do dalszego rozwoju.
